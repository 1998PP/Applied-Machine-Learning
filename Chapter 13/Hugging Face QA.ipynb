{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Question-Answering System with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "id = 'deepset/minilm-uncased-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(id)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(id, from_pt=True)\n",
    "pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9793134331703186, 'start': 0, 'end': 27, 'answer': 'Natural Language Processing'}\n"
     ]
    }
   ],
   "source": [
    "question = 'What does NLP stand for?'\n",
    "\n",
    "context = 'Natural Language Processing, or NLP, encompasses a variety of activities, \\\n",
    "           including text classification, keyword and topic extraction, text \\\n",
    "           summarization, and language translation. The accuracy of NLP models \\\n",
    "           has improved in recent years for a variety of reasons, not the least \\\n",
    "           of which are newer and better ways of converting words and sentences into \\\n",
    "           dense vector representations that incorporate word context, and a \\\n",
    "           relatively new neural-network architecture called the transformer that \\\n",
    "           can zero in on the most meaningful words and even differentiate \\\n",
    "           between different meanings of the same word.'\n",
    "\n",
    "output = pipe(question=question, context=context)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "question = 'When was TensorFlow released?'\n",
    "\n",
    "context = 'Machine learning isn\\'t hard when you have a properly engineered dataset \\\n",
    "           to work with. The reason it\\'s not hard is libraries such as Scikit-learn \\\n",
    "           and ML.NET, which reduce complex learning algorithms to a few lines of \\\n",
    "           code. Deep learning isn’t difficult, either, thanks to libraries such as \\\n",
    "           the Microsoft Cognitive Toolkit (CNTK), Theano, and PyTorch. But the \\\n",
    "           library that most of the world has settled on for building neural networks \\\n",
    "           is TensorFlow, an open-source framework created by Google that was \\\n",
    "           released under the Apache License 2.0 in 2015.'\n",
    "\n",
    "output = pipe(question=question, context=context)\n",
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrated into TensorFlow in 2019\n"
     ]
    }
   ],
   "source": [
    "question = 'Is Keras part of TensorFlow?'\n",
    "\n",
    "context =  'The learning curve for TensorFlow is rather steep. Another library \\\n",
    "            named Keras provides a simplified Python interface to TensorFlow \\\n",
    "            and has emerged as the Scikit of deep learning. Keras is all about \\\n",
    "            neural networks. It began life as a stand-alone project in 2015 \\\n",
    "            but was integrated into TensorFlow in 2019. Any code that you write \\\n",
    "            using TensorFlow’s built-in Keras module ultimately executes in \\\n",
    "            (and is optimized for) TensorFlow. Even Google recommends using the \\\n",
    "            Keras API.'\n",
    "\n",
    "output = pipe(question=question, context=context)\n",
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras\n"
     ]
    }
   ],
   "source": [
    "question = 'Is it better to use Keras or TensorFlow to build neural networks?'\n",
    "output = pipe(question=question, context=context)\n",
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load contexts and implement a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning isn’t hard when you have a properly engineered dataset to work with. The reason it’s not hard is libraries such as Scikit-learn and ML.NET, which reduce complex learning algorithms to a few lines of code. Deep learning isn’t difficult, either, thanks to libraries such as the Microsoft Cognitive Toolkit (CNTK), Theano, and PyTorch. But the library that most of the world has settled on for building neural networks is TensorFlow, an open-source framework created by Google that was released under the Apache License 2.0 in 2015.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TensorFlow isn’t limited to building neural networks. It is a framework for performing fast mathematical operations at scale using tensors, which are generalized versions of arrays. Tensors can represent scalar values (0-dimensional tensors), vectors (1D tensors), matrices (2D tensors), and so on. A neural network is basically a workflow for transforming tensors. The 3-layer perceptron featured in the previous chapter takes a 1D tensor containing two values as input, transforms it into a 1D tensor containing three values, and produces a 0D tensor as output. TensorFlow lets you define directed graphs that in turn define how tensors are computed. And unlike Scikit, it supports GPUs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The learning curve for TensorFlow is rather steep. Another library named Keras provides a simplified Python interface to TensorFlow and has emerged as the Scikit of deep learning. Keras is all about neural networks. It began life as a stand-alone project in 2015 but was integrated into TensorFlow in 2019. Any code that you write using TensorFlow’s built-in Keras module ultimately executes in (and is optimized for) TensorFlow. Even Google recommends using the Keras API.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keras offers two APIs for building neural networks: a sequential API and a functional API. The former is simpler and is sufficient for most neural networks. The latter is useful in more advanced scenarios such as networks with multiple outputs – for example, a classification output and a regression output, which is common in neural networks that perform object detection – or shared layers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s not difficult to use Scikit-learn to build machine-learning models that analyze text for sentiment, identify spam, and classify text in other ways. But today, state-of-the-art text classification is most often performed with neural networks. You already know how to build neural networks that accept numbers and images as input. Let’s build on that to learn how to construct deep-learning models that process text – a segment of deep learning known as natural language processing, or NLP for short.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0\n",
       "0                                                                                                                                                 Machine learning isn’t hard when you have a properly engineered dataset to work with. The reason it’s not hard is libraries such as Scikit-learn and ML.NET, which reduce complex learning algorithms to a few lines of code. Deep learning isn’t difficult, either, thanks to libraries such as the Microsoft Cognitive Toolkit (CNTK), Theano, and PyTorch. But the library that most of the world has settled on for building neural networks is TensorFlow, an open-source framework created by Google that was released under the Apache License 2.0 in 2015.\n",
       "1  TensorFlow isn’t limited to building neural networks. It is a framework for performing fast mathematical operations at scale using tensors, which are generalized versions of arrays. Tensors can represent scalar values (0-dimensional tensors), vectors (1D tensors), matrices (2D tensors), and so on. A neural network is basically a workflow for transforming tensors. The 3-layer perceptron featured in the previous chapter takes a 1D tensor containing two values as input, transforms it into a 1D tensor containing three values, and produces a 0D tensor as output. TensorFlow lets you define directed graphs that in turn define how tensors are computed. And unlike Scikit, it supports GPUs.\n",
       "2                                                                                                                                                                                                                          The learning curve for TensorFlow is rather steep. Another library named Keras provides a simplified Python interface to TensorFlow and has emerged as the Scikit of deep learning. Keras is all about neural networks. It began life as a stand-alone project in 2015 but was integrated into TensorFlow in 2019. Any code that you write using TensorFlow’s built-in Keras module ultimately executes in (and is optimized for) TensorFlow. Even Google recommends using the Keras API.\n",
       "3                                                                                                                                                                                                                                                                                                           Keras offers two APIs for building neural networks: a sequential API and a functional API. The former is simpler and is sufficient for most neural networks. The latter is useful in more advanced scenarios such as networks with multiple outputs – for example, a classification output and a regression output, which is common in neural networks that perform object detection – or shared layers.\n",
       "4                                                                                                                                                                                            It’s not difficult to use Scikit-learn to build machine-learning models that analyze text for sentiment, identify spam, and classify text in other ways. But today, state-of-the-art text classification is most often performed with neural networks. You already know how to build neural networks that accept numbers and images as input. Let’s build on that to learn how to construct deep-learning models that process text – a segment of deep learning known as natural language processing, or NLP for short."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Data/passages.csv', header=None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertModel.\n",
      "\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert_id = 'sebastian-hofstaetter/distilbert-dot-margin_mse-T2-msmarco'\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_id) \n",
    "bert_model = TFAutoModel.from_pretrained(bert_id, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    tokenized_text = bert_tokenizer(text, return_tensors='tf')\n",
    "    vectorized_text = bert_model(tokenized_text)[0][:, 0, :][0]\n",
    "    return vectorized_text\n",
    "\n",
    "contexts = data[0]\n",
    "vectorized_contexts = contexts.apply(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_best_contexts(query, contexts, max_matches=3):\n",
    "    scores = pd.Series(dtype='object')\n",
    "    tokenized_query = bert_tokenizer(query, return_tensors='tf')\n",
    "    vectorized_query = bert_model(tokenized_query)[0][:, 0, :][0]\n",
    "    \n",
    "    for idx, item in contexts.iteritems():\n",
    "        score = np.dot(vectorized_query, item)\n",
    "        scores = scores.append(pd.Series(score), ignore_index=True)\n",
    "\n",
    "    sorted_scores = scores.sort_values(ascending=False)[:max_matches]\n",
    "    return list(sorted_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are five versions of YOLO referred to as YOLOv1 through YOLOv5. There are also variations such as PP-YOLO and YOLO9000. YOLOv3 processes the image using a 13x13 grid, a 26x26 grid, and a 52x52 grid so it can detect objects large and small. It borrows the anchor-box concept from Faster R-CNN to predict nine bounding boxes per cell. YOLO’s primary weakness is that it has difficulty detecting small objects that are close together. This is a consequence of the fact that a given cell can only predict one class. \n",
      "\n",
      "While the R-CNN family of object-detection systems delivers unparalleled accuracy, it leaves something to be desired when it comes to real-time object detection of the type required by, say, self-driving cars. A paper entitled “You Only Look Once: Unified, Real-Time Object Detection” published in 2015 proposed an alternative to R-CNNs known as YOLO that revolutionized the way data scientists think about object detection. \n",
      "\n",
      "Until a few short years ago, most NMT models, including the one underlying Google Translate, were LSTM-based sequence-to-sequence models. In such models, one or more LSTM layers encode a tokenized input sequence representing the phrase to be translated into a vector. A second set of recurrent layers uses that vector as input and decodes it into a tokenized phrase in another language. The model accepts sequences as input and returns sequences as output, hence the term sequence-to-sequence model. A softmax output layer at the end outputs a set of probabilities for each token in the output sequence. If the maximum output phrase length that’s supported is 20 tokens, for example, and the vocabulary of the output language contains 20,000 words, then the output is 20 sets (one per token) of 20,000 probabilities. For each possible output token, the word selected is the word assigned the highest probability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'How many versions of YOLO are there?'\n",
    "indexes = get_best_contexts(question, vectorized_contexts)\n",
    "\n",
    "for idx in indexes:\n",
    "    print(f'{contexts[idx]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4768390357494354, 'start': 10, 'end': 14, 'answer': 'five'}\n"
     ]
    }
   ],
   "source": [
    "for idx in indexes:\n",
    "    output = pipe(question=question, context=contexts[idx], handle_impossible_answer=True)\n",
    "    \n",
    "    if output['start'] != output['end']:\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8453524112701416, 'start': 83, 'end': 94, 'answer': 'Mask R-CNNs'}\n"
     ]
    }
   ],
   "source": [
    "def show_answers(question, contexts, vectorized_contexts):\n",
    "    indexes = get_best_contexts(question, vectorized_contexts)\n",
    "    \n",
    "    for idx in indexes:\n",
    "        output = pipe(question=question, context=contexts[idx], handle_impossible_answer=True)\n",
    "\n",
    "        if output['start'] != output['end']:\n",
    "            print(output)\n",
    "\n",
    "question = 'What type of neural network supports instance segmentation?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5289613604545593, 'start': 371, 'end': 436, 'answer': 'it has difficulty detecting small objects that are close together'}\n"
     ]
    }
   ],
   "source": [
    "question = 'What is YOLO\\'s primary weakness?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.12999455630779266, 'start': 436, 'end': 446, 'answer': 'TensorFlow'}\n",
      "{'score': 0.2692341208457947, 'start': 0, 'end': 49, 'answer': 'The learning curve for TensorFlow is rather steep'}\n"
     ]
    }
   ],
   "source": [
    "question = 'Is TensorFlow difficult to learn?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
