{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons\n",
    "\n",
    "Neural networks come in many varieties. [Convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNNs), for example, excel at computer-vision tasks such as classifying images. [Recurrent neural networks](https://en.wikipedia.org/wiki/Recurrent_neural_network) (RNNs) find application in handwriting recognition and natural language processing (NLP), while [generative adversarial networks](https://en.wikipedia.org/wiki/Generative_adversarial_network), or GANs, enable computers to create art, music, and other content. But the first step in wrapping your head around deep learning is understanding what a neural network is and how it works.\n",
    "\n",
    "The simplest type of neural network is the [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron). It consists of nodes or neurons arranged in layers. The depth of the network is the number of layers; the width is the number of neurons in each layer, which can be different for every layer. State-of-the-art neural networks sometimes contain 100 or more layers and thousands of neurons in individual layers. A deep neural network is one that contains many layers, and it’s where the term deep learning derives from.\n",
    "\n",
    "The multilayer perceptron below contains three layers: an input layer with two neurons, a middle layer (also known as a hidden layer) with three neurons, and an output layer with one neuron. The network’s job is to take two floating-point values as input and produce a single floating-point number as output. Let's initialize this network with a set of weights and biases that enable it to add small numbers together, and then implement a `predict` function that performs a forward pass through the network.\n",
    "\n",
    "![](Images/network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "w0 = 0.9907079\n",
    "w1 = 1.0264927\n",
    "w2 = 0.01417504\n",
    "w3 = -0.8950311\n",
    "w4 = 0.88046944\n",
    "w5 = 0.7524377\n",
    "w6 = 0.794296\n",
    "w7 = 1.1687347\n",
    "w8 = 0.2406084\n",
    " \n",
    "# Biases\n",
    "b0 = -0.00070612\n",
    "b1 = -0.06846002\n",
    "b2 = -0.00055442\n",
    "b3 = -0.00000929\n",
    " \n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    " \n",
    "def predict(x1, x2):\n",
    "    h1 = (x1 * w0) + (x2 * w1) + b0\n",
    "    h2 = (x1 * w2) + (x2 * w3) + b1\n",
    "    h3 = (x1 * w4) + (x2 * w5) + b2\n",
    "    y = (relu(h1) * w6) + (relu(h2) * w7) + (relu(h3) * w8) + b3\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the network to add 2 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9895875277625037"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of weights and biases, using a neural network to make predictions is simplicity itself. It’s little more than multiplication and addition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
